{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # DataLoader加载器",
   "id": "66708411a2638feb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataLoader常见参数设置\n",
    "# dataset (Dataset) – dataset from which to load the data.\n",
    "# batch_size (int, optional) – how many samples per batch to load (default: 1).\n",
    "# shuffle (bool, optional) – True:打乱    False:不打乱    (default: False)\n",
    "# sampler (Sampler or Iterable, optional) – 采样策略\n",
    "    # sampler 决定每个 epoch 中 DataLoader 返回数据的顺序。\n",
    "\t# •\t不设置 sampler，且 shuffle=True → 系统默认用 RandomSampler\n",
    "\t# •\t设置了 sampler → 你自己决定样本顺序，就不能再设置 shuffle（会冲突）\n",
    "    # PyTorch 已经有一些常用的 sampler 实现：\n",
    "        # SequentialSampler:按顺序依次采样（适用于验证或不打乱的训练,默认在 shuffle = False 时使用）\n",
    "        # RandomSampler:随机打乱后采样（适用于训练时打乱数据,默认在 shuffle = True 时使用）\n",
    "        # WeightedRandomSampler:根据给定权重概率进行有放回采样（适用于类别不平衡问题)\n",
    "        # SubsetRandomSampler:从指定的索引子集中随机采样（适用于划分训练/验证集等情况）\n",
    "# num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
    "# drop_last (bool, optional) – 是否舍弃不足一组 batch_size 的数据\n",
    "    # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:24:41.109057Z",
     "start_time": "2025-04-21T14:24:40.335540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "id": "9d99a5f64d340550",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:24:50.267026Z",
     "start_time": "2025-04-21T14:24:49.861516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 准备测试集\n",
    "# 使用CIFAR10数据集，设置train=False表示加载测试集\n",
    "# transform=torchvision.transforms.ToTensor()将图片数据转换为Tensor格式\n",
    "test_data = torchvision.datasets.CIFAR10(\"./data/CIFAR10\", train = False, transform = torchvision.transforms.ToTensor())\n",
    "\n",
    "# 测试数据集中第一张图片及其target\n",
    "# datasets的__getitem__(index: int)会返回指定index的(img, target)\n",
    "img, target = test_data[0]\n",
    "print(img.shape)  # 打印图片的形状 (C, H, W)\n",
    "print(target)     # 打印图片对应的标签\n"
   ],
   "id": "981709a9e12e8c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "3\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:28:51.294804Z",
     "start_time": "2025-04-21T14:28:50.968874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用DataLoader加载测试数据集\n",
    "# batch_size=4表示每次加载4个样本\n",
    "# shuffle=True表示打乱数据顺序\n",
    "# num_workers=0表示数据加载在主进程中进行\n",
    "# drop_last=False表示保留最后不足一个batch的数据\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 64, shuffle = True, num_workers = 0, drop_last = False)\n",
    "\n",
    "# 创建SummaryWriter对象，用于将数据写入TensorBoard日志文件\n",
    "writer = SummaryWriter(\"./logs/5_DataLoader\")\n",
    "\n",
    "# 初始化step计数器\n",
    "step = 0\n",
    "\n",
    "# 遍历DataLoader加载的数据\n",
    "for data in test_loader:\n",
    "    if step >= 10:  # 限制只处理前10个batch\n",
    "        break\n",
    "    print(step, \":\")  # 打印当前step编号\n",
    "    imgs, targets = data  # 解包DataLoader返回的(imgs, targets)\n",
    "    writer.add_images(\"test_data\", imgs, step)  # 将图片数据写入TensorBoard\n",
    "    print(imgs.shape)  # 打印当前batch的图片形状 (batch_size, C, H, W)\n",
    "    print(targets)     # 打印当前batch的标签\n",
    "    step += 1          # 更新step计数器\n"
   ],
   "id": "18b5d26f2121ea54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([2, 2, 5, 3, 2, 7, 4, 0, 4, 3, 9, 5, 3, 8, 2, 6, 9, 7, 0, 8, 0, 3, 1, 6,\n",
      "        0, 5, 0, 2, 9, 5, 4, 7, 5, 1, 0, 7, 9, 3, 0, 8, 7, 2, 6, 4, 4, 9, 5, 2,\n",
      "        4, 7, 5, 0, 8, 0, 7, 0, 4, 7, 9, 7, 1, 8, 4, 5])\n",
      "1 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([6, 9, 9, 1, 2, 1, 1, 6, 5, 6, 2, 5, 0, 4, 7, 5, 9, 1, 1, 7, 6, 4, 4, 3,\n",
      "        2, 9, 7, 5, 6, 1, 4, 6, 6, 9, 1, 3, 5, 1, 9, 7, 5, 0, 6, 6, 5, 2, 8, 7,\n",
      "        0, 2, 2, 7, 1, 6, 4, 9, 5, 8, 1, 8, 0, 7, 9, 5])\n",
      "2 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([2, 8, 0, 7, 4, 6, 5, 6, 8, 4, 4, 6, 5, 8, 0, 9, 5, 4, 4, 6, 8, 9, 8, 9,\n",
      "        1, 9, 2, 1, 6, 2, 1, 2, 3, 4, 1, 7, 8, 8, 2, 8, 7, 8, 5, 3, 0, 8, 5, 5,\n",
      "        7, 5, 9, 2, 5, 7, 5, 8, 3, 6, 0, 8, 1, 6, 9, 3])\n",
      "3 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([9, 4, 9, 4, 8, 0, 2, 8, 1, 5, 9, 1, 8, 5, 1, 7, 8, 5, 4, 8, 9, 3, 3, 4,\n",
      "        0, 0, 1, 7, 8, 5, 8, 0, 3, 7, 8, 8, 3, 5, 5, 8, 3, 7, 2, 1, 5, 7, 5, 2,\n",
      "        2, 3, 3, 9, 7, 2, 3, 9, 9, 3, 3, 0, 4, 7, 5, 7])\n",
      "4 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([7, 0, 8, 7, 0, 9, 6, 0, 8, 5, 9, 8, 7, 4, 6, 3, 8, 6, 7, 1, 0, 0, 3, 6,\n",
      "        7, 7, 8, 6, 5, 5, 7, 9, 0, 8, 5, 9, 7, 6, 0, 0, 3, 7, 7, 0, 1, 4, 3, 1,\n",
      "        3, 1, 8, 8, 2, 1, 1, 5, 6, 1, 0, 2, 8, 3, 9, 3])\n",
      "5 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([1, 1, 8, 0, 4, 2, 1, 9, 2, 9, 8, 4, 8, 0, 5, 3, 0, 5, 6, 6, 1, 4, 0, 2,\n",
      "        3, 7, 4, 0, 1, 6, 4, 4, 1, 3, 2, 0, 0, 1, 8, 1, 9, 7, 3, 0, 2, 8, 9, 7,\n",
      "        5, 2, 0, 7, 5, 1, 0, 4, 8, 4, 4, 7, 0, 9, 4, 0])\n",
      "6 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([0, 5, 1, 2, 4, 9, 9, 0, 9, 0, 8, 1, 9, 9, 8, 5, 2, 3, 7, 8, 2, 4, 9, 1,\n",
      "        6, 7, 9, 7, 5, 1, 1, 1, 9, 0, 8, 8, 0, 6, 2, 9, 9, 5, 3, 9, 2, 1, 3, 4,\n",
      "        1, 9, 9, 1, 0, 7, 1, 2, 9, 0, 2, 2, 9, 5, 5, 8])\n",
      "7 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([7, 5, 5, 9, 6, 7, 6, 5, 3, 0, 0, 6, 4, 0, 6, 2, 3, 1, 8, 1, 5, 8, 0, 4,\n",
      "        6, 3, 5, 1, 4, 8, 5, 3, 5, 7, 2, 2, 9, 3, 6, 5, 0, 8, 1, 3, 2, 3, 8, 6,\n",
      "        0, 1, 4, 8, 2, 0, 1, 5, 4, 3, 0, 3, 2, 9, 7, 8])\n",
      "8 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([1, 0, 1, 9, 2, 9, 3, 8, 6, 5, 6, 3, 0, 6, 9, 5, 8, 7, 5, 9, 5, 4, 7, 0,\n",
      "        7, 0, 3, 9, 0, 3, 2, 3, 4, 0, 1, 6, 2, 9, 4, 1, 3, 1, 6, 5, 5, 3, 3, 0,\n",
      "        1, 0, 3, 8, 9, 1, 0, 7, 4, 9, 3, 3, 1, 4, 7, 6])\n",
      "9 :\n",
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([5, 9, 7, 9, 2, 8, 3, 3, 2, 7, 4, 9, 4, 4, 4, 3, 4, 9, 3, 9, 0, 4, 9, 3,\n",
      "        0, 6, 1, 4, 8, 3, 0, 2, 1, 1, 5, 8, 9, 4, 0, 8, 0, 6, 0, 0, 5, 7, 6, 3,\n",
      "        7, 4, 1, 1, 1, 3, 0, 5, 8, 2, 8, 6, 1, 6, 1, 5])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:29:14.868279Z",
     "start_time": "2025-04-21T14:29:14.866160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 关闭SummaryWriter，释放资源\n",
    "writer.close()"
   ],
   "id": "a9ee9ad8b78bd43f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "650d5cc0ff5bc024"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
