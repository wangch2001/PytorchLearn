{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义模型结构",
   "id": "e33cbfb4ec4c56e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5c299-ff96-4979-bf9d-8d16896a2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential\n",
    "#     是一个容器（容器模块），会按照定义的顺序，把多个 nn.Module（层）组合在一起，前向传播时自动按顺序执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f5938e-fb42-4877-9291-9ac9df6ce04c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T03:01:16.662171Z",
     "start_time": "2025-04-15T03:01:16.659412Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用法1:\n",
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3, 16, kernel_size=3, padding=1), # 卷积层\n",
    "#     nn.BatchNorm2d(16),                         # 批归一化层\n",
    "#     nn.ReLU(),                                  # 激活函数\n",
    "#     nn.MaxPool2d(2, 2)                          # 最大池化层\n",
    "# )\n",
    "\n",
    "# 用法2（推荐）:\n",
    "# from collections import OrderedDict\n",
    "# nn.Sequential(OrderedDict([\n",
    "#     ('conv', nn.Conv2d(3, 16, 3, padding=1)),   # 命名的卷积层\n",
    "#     ('bn', nn.BatchNorm2d(16)),                 # 命名的批归一化层\n",
    "#     ('relu', nn.ReLU()),                        # 命名的激活函数\n",
    "#     ('pool', nn.MaxPool2d(2, 2))                # 命名的最大池化层\n",
    "# ]))\n",
    "\n",
    "# 更推荐用法2的原因：\n",
    "# 1. 可以通过名字访问每一层，方便调试和修改\n",
    "    # model['conv1']  # 立刻知道是卷积层\n",
    "    # model['relu1']  # 清晰知道是哪一层\n",
    "# 2.可按名字访问/替换层，调试更方便\n",
    "    # model['relu1'] = nn.LeakyReLU()  # 替换激活函数\n",
    "# 3.与 state_dict() 更好配合\n",
    "    # state_dict() 是模型中所有可学习参数（权重和偏置）以及某些缓冲（如 BatchNorm 的 running_mean）的字典表示。\n",
    "    # 它是 PyTorch 保存/加载模型的核心机制，格式为：\n",
    "    #     OrderedDict({\n",
    "    #     'layer_name.parameter_name': tensor\n",
    "    #     })\n",
    "    # 在查看模型参数时，使用 OrderedDict 可以更清晰地看到每一层的参数名称和对应的 tensor。\n",
    "    # from collections import OrderedDict\n",
    "    # \n",
    "    # model = nn.Sequential(OrderedDict([\n",
    "    #     ('conv1', nn.Conv2d(3, 16, 3)),  # 第一层卷积\n",
    "    #     ('relu1', nn.ReLU()),           # 第一层激活函数\n",
    "    #     ('conv2', nn.Conv2d(16, 32, 3)) # 第二层卷积\n",
    "    # ]))\n",
    "    # \n",
    "    # for name, param in model.state_dict().items():\n",
    "    #     print(name)\n",
    "    # 上述代码输出如下：\n",
    "    #     conv1.weight\n",
    "    #     conv1.bias\n",
    "    #     conv2.weight\n",
    "    #     conv2.bias\n",
    "# 4.支持模型可视化工具\n",
    "    # 如使用 torchsummary 或 torchviz、TensorBoard 可视化时，命名的层更容易在图中被标记出来，结构层次一目了然。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87132c98-37f2-427d-9565-53d2a86484f3",
   "metadata": {},
   "source": [
    "本次教程使用LeNet作为示例，想了解[LeNet](https://zh.d2l.ai/chapter_convolutional-neural-networks/lenet.html)的可以直接点击链接学习。   \n",
    "LeNet的结构如下：   \n",
    "![LeNet结构](images/LeNet.png)."
   ]
  },
  {
   "cell_type": "code",
   "id": "c61c2976-3a2a-47ba-9f44-c50ddb7a300e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:03:14.887527Z",
     "start_time": "2025-04-22T08:03:14.170982Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "24d1000f-c003-48c8-8414-d3d9b760d543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:03:16.773801Z",
     "start_time": "2025-04-22T08:03:16.767467Z"
    }
   },
   "source": [
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()\n",
    "        \n",
    "        # # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, \n",
    "        # #                 groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        # self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, padding = 2)\n",
    "        # # torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)[source]\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size = 2)\n",
    "        # self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 5, padding = 2)\n",
    "        # self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        # self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, padding = 2)\n",
    "        # self.maxpool3  = nn.MaxPool2d(kernel_size = 2)\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.linear1 = nn.Linear(1024, 64)\n",
    "        # self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "        # 如此便可以省略掉上面的部分\n",
    "        # self.model1 = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, padding = 2),\n",
    "        #     nn.MaxPool2d(kernel_size = 2),\n",
    "        #     nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 5, padding = 2),\n",
    "        #     nn.MaxPool2d(kernel_size = 2),\n",
    "        #     nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, padding = 2),\n",
    "        #     nn.MaxPool2d(kernel_size = 2),\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(1024, 64),\n",
    "        #     nn.Linear(64, 10)\n",
    "        # )\n",
    "\n",
    "        # 更推荐这种写法\n",
    "        self.model1 = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2)),  # 第一层卷积\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),                                         # 第一层池化\n",
    "            ('conv2', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)),# 第二层卷积\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=2)),                                         # 第二层池化\n",
    "            ('conv3', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)),# 第三层卷积\n",
    "            ('pool3', nn.MaxPool2d(kernel_size=2)),                                         # 第三层池化\n",
    "            ('flatten', nn.Flatten()),                                                     # 展平层\n",
    "            ('fc1', nn.Linear(1024, 64)),                                                  # 全连接层1\n",
    "            ('fc2', nn.Linear(64, 10))                                                     # 全连接层2（输出10类）\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.conv1(x)\n",
    "        # x = self.maxpool(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.maxpool2(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = self.maxpool3(x)\n",
    "        # x = self.flatten(x)\n",
    "        # x = self.linear1(x)\n",
    "        # x = self.linear2(x)\n",
    "        x = self.model1(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e619bbef-29cc-4224-9628-0fb292547959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:03:21.153928Z",
     "start_time": "2025-04-22T08:03:21.115072Z"
    }
   },
   "source": [
    "# 实例化模型\n",
    "tudui = Tudui()\n",
    "print(tudui)\n",
    "\n",
    "# 创建一个输入张量，形状为 (64, 3, 32, 32)，表示 64 个 32x32 的 RGB 图像\n",
    "input = torch.ones((64, 3, 32, 32))\n",
    "\n",
    "# 通过模型进行前向传播\n",
    "output = tudui(input)\n",
    "print(output.shape)  # 输出形状应为 (64, 10)，表示 64 个样本的 10 类预测"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tudui(\n",
      "  (model1): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "56eaf99c-6c59-47cb-b8c0-740ca0ac1085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:03:43.704074Z",
     "start_time": "2025-04-22T08:03:43.566887Z"
    }
   },
   "source": [
    "# 使用 TensorBoard 可视化模型结构\n",
    "writer = SummaryWriter(\"./logs/12_nn_Sequential\")\n",
    "writer.add_graph(tudui, input)  # 将模型和输入添加到 TensorBoard\n",
    "writer.close()"
   ],
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
