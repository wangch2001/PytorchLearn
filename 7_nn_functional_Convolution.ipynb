{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN介绍",
   "id": "6ba380c68e06f73b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T15:08:01.607898Z",
     "start_time": "2025-04-21T15:08:01.605684Z"
    }
   },
   "source": [
    "# 这里重点说明一下 torch.nn 和 torch.nn.functional 有何区别，下面用两者中的 convl2d 来举例说明：\n",
    "# torch.nn 是一个类，模型的参数 weight 和 bias 会自动注册，我们只需要给出其形状即可，weight 和 bias 会在后续网络的训练中自动更新优化\n",
    "# torch.nn.functional 只是一个函数，我们需要传入具体的 weight 和 bias 值，后续两者是否会随则会反向传播进行优化要看两者是否被加入到了参数列表"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:08:02.239096Z",
     "start_time": "2025-04-21T15:08:01.610964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ],
   "id": "970b9fbd54044d4d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:08:03.019616Z",
     "start_time": "2025-04-21T15:08:03.012757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "                      [0, 1, 2, 3, 1],\n",
    "                      [1, 2, 1, 0, 0],\n",
    "                      [5, 2, 3, 1, 1],\n",
    "                      [2, 1, 0, 1, 1]])\n",
    "kernel = torch.tensor([[1, 2, 1],\n",
    "                       [0, 1, 0],\n",
    "                       [2, 1, 0]])\n",
    "# 打印输入张量和卷积核的形状\n",
    "print(input.shape)  # 输出: torch.Size([5, 5])\n",
    "print(kernel.shape)  # 输出: torch.Size([3, 3])\n"
   ],
   "id": "6d57a209aab9c64b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:09:07.085276Z",
     "start_time": "2025-04-21T15:09:07.080939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.reshape\n",
    "    # Args:\n",
    "    #     input (Tensor): the tensor to be reshaped    想要变换的张量\n",
    "    #     shape (tuple of int): the new shape          想要变换为的形状\n",
    "\n",
    "# torch.nn.functional.conv2d\n",
    "    # Args:\n",
    "    #     input,           输入，必须得是 (minibatch,in_channels,iH,iW) 的张量\n",
    "    #     weight,          卷积核（权重），必须得是 (out_channels,in_channels / groups,kH,kW) 的张量\n",
    "    #     bias=None,       偏置值，必须是 1 * out_channels 形状的张量\n",
    "    #     stride=1,\n",
    "    #     padding=0,\n",
    "    #     dilation=1,\n",
    "    #     groups=1\n",
    "# input: (5, 5) -> (1, 1, 5, 5) 表示 (batch_size, channels, height, width)\n",
    "# kernel: (3, 3) -> (1, 1, 3, 3) 表示 (out_channels, in_channels, kernel_height, kernel_width)\n",
    "input = torch.reshape(input, (1, 1, 5, 5))\n",
    "kernel = torch.reshape(kernel, (1, 1, 3, 3))\n",
    "print(input.shape)  # 输出: torch.Size([1, 1, 5, 5])\n",
    "print(kernel.shape)  # 输出: torch.Size([1, 1, 3, 3])\n"
   ],
   "id": "13298edefea3df92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:10:04.683180Z",
     "start_time": "2025-04-21T15:10:04.673238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 torch.nn.functional.conv2d 进行卷积操作\n",
    "# 参数解释:\n",
    "# input: 输入张量，形状为 (batch_size, in_channels, height, width)\n",
    "# weight: 卷积核，形状为 (out_channels, in_channels / groups, kernel_height, kernel_width)\n",
    "# stride: 步幅，控制卷积核移动的步长\n",
    "# padding: 填充，控制边界的填充大小\n",
    "output1 = F.conv2d(input, kernel, stride=1)  # 步幅为 1\n",
    "print(output1)  # 输出卷积结果\n"
   ],
   "id": "c702bd2a46c8d629",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[10, 12, 12],\n",
      "          [18, 16, 16],\n",
      "          [13,  9,  3]]]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:11:52.538887Z",
     "start_time": "2025-04-21T15:11:52.532713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这里必须使用类型转换\n",
    "# 使用 torch.tensor([...]) 创建 input 和 kernel 时，默认它们是 LongTensor（整型）,torch.ones 创建的默认是浮点类型\n",
    "# 而 F.conv2d 要求所有输入（包括 input、kernel、bias）类型必须 一致，通常是 float32（torch.float）\n",
    "# 虽然下面的示例采用了 conv2d_bias = conv2d_bias.long() 这样的转换，但是一般不推荐，这例子是做一个反面教材\n",
    "# 一般更推荐将所有传入参数都转换为浮点数，因为这样会让内部计算更快，有如下两种方法：\n",
    "# 方法1（更推荐）:在定义参数的时候直接明确为浮点数\n",
    "    # input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "    #                       [0, 1, 2, 3, 1],\n",
    "    #                       [1, 2, 1, 0, 0],\n",
    "    #                       [5, 2, 3, 1, 1],\n",
    "    #                       [2, 1, 0, 1, 1]], dtype=torch.float)\n",
    "\n",
    "    # kernel = torch.tensor([[1, 2, 1],\n",
    "    #                        [0, 1, 0],\n",
    "    #                        [2, 1, 0]], dtype=torch.float)\n",
    "\n",
    "# 方法2（不推荐）：\n",
    "    # input = input.float()\n",
    "    # kernel = kernel.float()\n",
    "conv2d_bias = torch.ones(1)\n",
    "conv2d_bias = conv2d_bias.long()\n",
    "print(conv2d_bias)\n",
    "print(conv2d_bias.shape)\n",
    "output2 = F.conv2d(input, kernel, bias = conv2d_bias, stride = 1)\n",
    "print(output2)"
   ],
   "id": "62519e17e5db365e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "torch.Size([1])\n",
      "tensor([[[[11, 13, 13],\n",
      "          [19, 17, 17],\n",
      "          [14, 10,  4]]]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:12:08.934341Z",
     "start_time": "2025-04-21T15:12:08.931548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 关于 stride 参数\n",
    "# stride 控制卷积核移动的步长，步长越大，输出张量的尺寸越小\n",
    "output3 = F.conv2d(input, kernel, stride=2)  # 步幅为 2\n",
    "print(output3)  # 输出卷积结果\n"
   ],
   "id": "806d8f85fe76bb4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[10, 12],\n",
      "          [13,  3]]]])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:12:32.594512Z",
     "start_time": "2025-04-21T15:12:32.590757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 关于 padding 参数\n",
    "# padding 用于在输入张量的边界添加额外的值，通常是 0\n",
    "# padding 的大小会影响输出张量的尺寸\n",
    "output4 = F.conv2d(input, kernel, stride=1, padding=1)  # 填充大小为 1\n",
    "print(output4)  # 输出卷积结��\n"
   ],
   "id": "4b0aeef7fc9561b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  3,  4, 10,  8],\n",
      "          [ 5, 10, 12, 12,  6],\n",
      "          [ 7, 18, 16, 16,  8],\n",
      "          [11, 13,  9,  3,  4],\n",
      "          [14, 13,  9,  7,  4]]]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c99ca0379eccdfc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
